
# About
This repository aims to evaluate the robustness of quantized CNNs with approximate computing against adversarial attacks.
The repository includes:  

- Code for training ResNet models on the CIFAR10 and CIFAR100 datasets.  
- Support for fast adversarial training, available in the `fast_adversarial` directory.  
- Implementation of approximate convolutions using the **TransAxx** framework.  
- A directory dedicated to simulating adversarial attacks on CNN models. 

## Installation
Execute the following commands to install the necessary dependencies.

Open a terminal and intall ninja-build
```bash
sudo apt update
sudo apt install ninja-build
```
Install all the necessary dependecies using conda (requires anaconda or miniconda https://www.anaconda.com/download)
```bash

conda env create -f environment.yml
```

In order to use all 255 multipliers for the TransAxx model, it is necessary to install 7-zip and extract the `axx_mults_8x8.7z` file located at `transaxx/ext_modules/include/nn/cuda/axx_mults`. You can download 7-zip at https://www.7-zip.org/download.html

Finally, modify the PYTHONPATH as follows:
```bash
export PYTHONPATH="${PYTHONPATH}:your_path_to_this_folder/transaxx/:your_path_to_this_folder/neural_networks:your_path_to_this_folder/benchmark_CIFAR10:your_path_to_this_folder/approximate_multiplier$"$
```

# Usage

Focus on the `neural_networks`, `fast_adversarial`, and `adversarial` directories. The other directories primarily contain dependencies, and you won’t need to run any scripts from them.  

## Model Training and Evaluation
To train CIFAR-10 NNs you can use the script "train_cifar10.py", you can check the options by executing the following command: 
> python neural_networks/CIFAR10/train_cifar10.py --help


As an example, run the following command:
> python neural_networks/CIFAR10/train_cifar10.py --neural-network resnet8 --execution-type quant

The available execution types are the following:
- **`float`**: Models are defined using regular layers from `torch.nn`.
- **`quant`**: These are quantized models, the quantization is achieved using custom layer definitions in `neural_networks/custom_layers.py`.
- **`transaxx`**: These are quantized models that also support approximate multipliers. Quantization is done using `pytorch-quantization`, and custom layers are defined in `transaxx/layers`. For more details about the `transaxx` layer definitions, refer to the `transaxx/layers/` directory.

To evaluate a model’s accuracy, run the following command:
> python neural_networks/CIFAR10/test_transaxx.py --neural-network resnet32 --execution-type quant --param-execution-type float

In this example, we evaluate the accuracy of a `resnet32` model with `quant` execution type, using pre-trained parameters from a `resnet32` model with `float` execution type.

In general, there are three execution types available, and you can load pre-trained parameters from any of them. This allows for nine possible combinations, such as loading parameters from a `float` model into a `transaxx` model, or from `quant` into `transaxx`, and so on.
 

## Adversarial Training
The `fast_adversarial` directory contains training scripts using an FGSM adversary, with the goal of increasing the model's accuracy when under attack. For a more detailed overview of this repository see the README in the `fast_adversarial` directory.

For example running the following command:
> python fast_adversarial/CIFAR10/train_resnet.py --neural-network resnet32 --execution-type transaxx --epochs 112 --reload 1

Would instantiate a resnet32 model with pre-trained parameters (because reload is 1), and continue training for a number of epochs equal to the difference between the number of epochs passed as argument and the number of epochs used for the pre-trained parameters.
The adversarially trained parameters are saved in `fast_adversarial/AT_models`.

## Attack Simulation

To simulate attacks on CNNs, the first step is generating perturbed data (adversarial images). This can be done using the following command:

> python adversarial/generate_adv_data.py --neural-network resnet8 --execution-type quant 

In this command:
- A resnet8 model is instantiated.
- You are prompted to select the type of attack and its parameters.
- Adversarial images are generated based on this model and saved in the `adversarial/adv_data` directory.

To evaluate a model's accuracy under attack, use the resnet_attack_eval.py script. For instance:

> python adversarial/resnet_attack_eval.py --neural-network resnet32 --execution-type quant --adv-neural-network resnet8 --adv-execution-type quant

Here:
- A resnet32 model is instantiated and evaluated.
- The adversarial data generated by the resnet8 model in the previous step is used to test the resnet32 model's accuracy.


## Acknowledgments
This project makes use of the following third-party libraries:

-[MARLIN](https://github.com/vlsi-lab/MARLIN)
Used for defining the CNN models and providing the script to train them. 

-[fast_adversarial](https://github.com/locuslab/fast_adversarial/tree/master)
Used for adversarial training of the CNN models. 

-[TransAxx](https://github.com/dimdano/transaxx)
Used for supporting approximate convolutional layers.

-[Adversarial-Attacks-PyTorch](https://github.com/Harry24k/adversarial-attacks-pytorch)
Used to generate adversarial data for simulating adversarial attacks.
